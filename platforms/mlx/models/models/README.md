# Модели Whisper для VTTv2

## MLX Whisper (основной метод, рекомендуется)

VTTv2 использует **MLX Whisper** как основной движок транскрипции. Модель скачивается автоматически при первом использовании.

### Автоматическая загрузка

При первом запуске транскрипции MLX Whisper автоматически скачает модель `mlx-community/whisper-medium` из Hugging Face (~1.5 GB).

**Преимущества:**
- ✅ Оптимально для MacBook Air M1 с 8GB RAM
- ✅ Автоматическая загрузка - не требует ручной установки
- ✅ Оптимизировано для Apple Silicon (M1/M2/M3/M4)
- ✅ Эффективное использование памяти
- ✅ Высокая скорость транскрипции

### Выбор модели MLX

Модель можно изменить в `config.yaml`:

```yaml
transcription:
  engine: mlx_whisper
  mlx_whisper:
    model_name: "mlx-community/whisper-medium"  # Оптимально для M1 8GB
```

**Доступные модели:**
- `mlx-community/whisper-tiny` - самая быстрая, наименьшая точность
- `mlx-community/whisper-small` - баланс скорости и качества
- `mlx-community/whisper-medium` - **рекомендуется для M1 8GB** ⭐
- `mlx-community/whisper-large-v3` - максимальная точность (требует больше памяти)

## Whisper.cpp (опционально, для fallback)

Если вы хотите использовать whisper.cpp как альтернативный движок, нужно скачать модель вручную.

### Модель Medium Q5_0 (рекомендуется для M1 8GB)

Для MacBook Air M1 с 8GB RAM рекомендуется использовать квантизированную модель **ggml-medium-q5_0.bin** (~514 MB).

#### Скачивание модели

```bash
mkdir -p models
cd models
curl -L "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium-q5_0.bin" -o ggml-medium-q5_0.bin
cd ..
```

#### Проверка установки

```bash
ls -lh models/ggml-medium-q5_0.bin
# Должен показать размер ~514 MB
```

### Другие модели для whisper.cpp

Если нужна другая модель:

- **ggml-medium-q5_0.bin** (~514 MB) - оптимально для M1 8GB ⭐
- **ggml-small-q5_0.bin** (~466 MB) - быстрее, но менее точно
- **ggml-base-q5_0.bin** (~142 MB) - самая быстрая, наименьшая точность
- **ggml-large-v3-q5_0.bin** (~1.0 GB) - максимальная точность (может быть тяжело для M1 8GB)

Скачать их можно аналогично, заменив `medium-q5_0` на нужную модель в URL.

### Конфигурация whisper.cpp

После скачивания модели путь в `config.yaml` должен быть:

```yaml
transcription:
  engine: whisper_cpp
  whisper_cpp:
    model_path: "./models/ggml-medium-q5_0.bin"
```

### Примечания

- Модели whisper.cpp не включены в репозиторий из-за размера
- Модель нужно скачать один раз после клонирования репозитория
- После установки приложение работает полностью офлайн
- Модель Medium Q5_0 обеспечивает хороший баланс качества и скорости для M1 с 8GB RAM

## Сравнение методов

| Характеристика | MLX Whisper | Whisper.cpp |
|---------------|-------------|-------------|
| **Установка** | Автоматическая | Ручная |
| **Размер модели** | ~1.5 GB | ~514 MB (Medium Q5_0) |
| **Оптимизация** | Apple Silicon | Metal/Core ML |
| **Скорость** | Очень высокая | Высокая |
| **Память** | Эффективное использование | Требует настройки |
| **Рекомендация** | ✅ Для M1 8GB | Опционально для fallback |

**Вывод:** Используйте MLX Whisper как основной метод. Whisper.cpp нужен только если вы хотите альтернативный движок.
